{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:22:59.381128Z",
     "start_time": "2025-01-16T22:22:42.012988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import datetime\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def select_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    folder_path = filedialog.askdirectory(initialdir=r\"H:\\Pitching\\Data\", title=\"Select Folder\")\n",
    "    if folder_path:\n",
    "        copy_and_move_files(folder_path)\n",
    "\n",
    "\n",
    "def extract_name(folder_name):\n",
    "    # Extract the full name from the folder name\n",
    "    # Assuming the folder name is in the format \"Last, First\"\n",
    "    parts = folder_name.split(\", \")\n",
    "    if len(parts) == 2:\n",
    "        first_name = parts[1].strip()\n",
    "        last_name = parts[0].strip()\n",
    "        full_name = f\"{first_name} {last_name}\"\n",
    "    else:\n",
    "        full_name = folder_name.strip()\n",
    "    return full_name\n",
    "\n",
    "\n",
    "def copy_and_move_files(base_path):\n",
    "    # Get the base folder name\n",
    "    base_folder = os.path.basename(base_path)\n",
    "\n",
    "    # Get list of folders in the base path\n",
    "    folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "    # Sort folders by creation time\n",
    "    folders.sort(key=lambda x: os.path.getctime(os.path.join(base_path, x)), reverse=True)\n",
    "\n",
    "    if not folders:\n",
    "        print(\"No folders found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    latest_folder = folders[0]\n",
    "    folder_path = os.path.join(base_path, latest_folder)\n",
    "\n",
    "    # Get creation time of the latest folder\n",
    "    creation_time = os.path.getctime(folder_path)\n",
    "    creation_date = datetime.datetime.fromtimestamp(creation_time).strftime('%m-%d-%y')\n",
    "\n",
    "    # Find the files to copy and rename\n",
    "    files_to_copy_rename = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower() == 'session.xml' or file.lower() == 'session_data.xml':\n",
    "            files_to_copy_rename.append(file)\n",
    "\n",
    "    if not files_to_copy_rename:\n",
    "        print(\"No XML files named 'session.xml' or 'session_data.xml' found in the latest folder.\")\n",
    "        return\n",
    "\n",
    "    # Construct new file names\n",
    "    new_file_names = []\n",
    "    initials = extract_name(base_folder)\n",
    "    for file in files_to_copy_rename:\n",
    "        if file.lower() == 'session.xml':\n",
    "            new_file_name = f\"session_{initials}_{creation_date}.xml\"\n",
    "        elif file.lower() == 'session_data.xml':\n",
    "            new_file_name = f\"session_data_{initials}_{creation_date}.xml\"\n",
    "        else:\n",
    "            continue\n",
    "        new_file_names.append(new_file_name)\n",
    "\n",
    "    # Create temporary directory to store renamed copies\n",
    "    temp_dir = os.path.join(base_path, \"temp_rename\")\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    # Copy and rename the files to the temporary directory\n",
    "    for original_file, new_file_name in zip(files_to_copy_rename, new_file_names):\n",
    "        original_file_path = os.path.join(folder_path, original_file)\n",
    "        new_file_path = os.path.join(temp_dir, new_file_name)\n",
    "        shutil.copyfile(original_file_path, new_file_path)\n",
    "        print(f\"File '{original_file}' copied and renamed to: {new_file_path}\")\n",
    "\n",
    "    # Copy the renamed files to the destination folder\n",
    "    new_folder_path = r\"G:\\My Drive\\Pitching Data\\New Data\"\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "    for new_file_name in new_file_names:\n",
    "        temp_file_path = os.path.join(temp_dir, new_file_name)\n",
    "        destination_file_path = os.path.join(new_folder_path, new_file_name)\n",
    "        shutil.copyfile(temp_file_path, destination_file_path)\n",
    "        print(f\"File '{new_file_name}' copied to: {destination_file_path}\")\n",
    "\n",
    "    # Clean up temporary directory\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "# Prompt user to select the folder\n",
    "select_folder()\n",
    "\n",
    "\n",
    "# Source and destination directory paths\n",
    "source_dir = r\"G:\\My Drive\\Pitching Data\\New Data\"\n",
    "destination_dir = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\"\n",
    "\n",
    "# Iterate over files in the source directory\n",
    "for file_name in os.listdir(source_dir):\n",
    "    if file_name.endswith('.xml'):\n",
    "        source_file_path = os.path.join(source_dir, file_name)\n",
    "        destination_file_path = os.path.join(destination_dir, file_name)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "        print(f\"File '{file_name}' moved to: {destination_file_path}\")\n",
    "\n",
    "print(\"XML files copied successfully!\")\n",
    "\n",
    "# This code is *chef's kiss* perfect. Does everything for parsing for variables, iterates over it\n",
    "# multiple times, and includes the specific filename for each trial. I love it.\n",
    "\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"Cover_Page.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Drop the table if it exists\n",
    "cursor.execute('DROP TABLE IF EXISTS variables')\n",
    "\n",
    "# Create the variables table\n",
    "cursor.execute('''\n",
    "   CREATE TABLE variables (\n",
    "       id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "       session_data_id TEXT NOT NULL,\n",
    "       file_name TEXT NOT NULL,\n",
    "       Pitch TEXT,\n",
    "       Score REAL,\n",
    "       Linear_Pelvis_Speed REAL,\n",
    "       HSS_Footplant REAL,\n",
    "       Pelvis_Ang_Footplant REAL,\n",
    "       Trunk_Ang_Footplant REAL,\n",
    "       Pelvic_Obl REAL,\n",
    "       Front_Leg_Brace REAL,\n",
    "       Front_Leg_Var_Val REAL,\n",
    "       Lead_Leg_Midpoint REAL,\n",
    "       Lead_Leg_GRF_y REAL,\n",
    "       Lead_Leg_GRF_z REAL,\n",
    "       Lead_Leg_GRF_x REAL,\n",
    "       Horizontal_Abduction REAL,\n",
    "       Shld_ER_Footplant REAL,\n",
    "       Shld_ER_Max REAL,\n",
    "       Lateral_Trunk_Tilt REAL,\n",
    "       Pelvis_Ang_Velo REAL,\n",
    "       Torso_Ang_Velo REAL,\n",
    "       Arm_Ang_Velo REAL,\n",
    "       MPH REAL,\n",
    "       Trunk_Ang_MER REAL,\n",
    "       Trunk_Ang_Rel REAL,\n",
    "       Pelvis_Ang_MER REAL,\n",
    "       Pelvis_Ang_Rel REAL,\n",
    "       HSS_MER REAL,\n",
    "       HSS_Rel REAL,\n",
    "       Front_Leg_Footplant REAL,\n",
    "       Front_Leg_MER REAL,\n",
    "       Front_Leg_Rel REAL,\n",
    "       Abduction_Max REAL,\n",
    "       Hand_Ang_Velo REAL,\n",
    "       Stride_Length REAL,\n",
    "       Arm_Slot REAL,\n",
    "       Weight REAL\n",
    "   )\n",
    "''')\n",
    "\n",
    "# Commit the changes before proceeding to parsing XML files\n",
    "conn.commit()\n",
    "\n",
    "# List of XML files to parse (replace this with your actual directory path)\n",
    "directory_path = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\"\n",
    "\n",
    "while True:\n",
    "    # Get a list of XML files in the specified directory\n",
    "    xml_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith(\".xml\")]\n",
    "\n",
    "    # Track the number of new data entries\n",
    "    new_data_entries = 0\n",
    "\n",
    "    for file_name in xml_files:\n",
    "        try:\n",
    "            # Check if the file has already been processed\n",
    "            cursor.execute('SELECT COUNT(*) FROM variables WHERE file_name = ?', (file_name,))\n",
    "            count = cursor.fetchone()[0]\n",
    "\n",
    "            if count == 0:\n",
    "                # Parse the XML file\n",
    "                tree = ET.parse(file_name)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                # Extract session_data_id from the file name\n",
    "                session_data_id_match = re.search(r\"session_data_(.+)\\.xml\", file_name)\n",
    "                if session_data_id_match:\n",
    "                    session_data_id = session_data_id_match.group(1)\n",
    "                else:\n",
    "                    session_data_id = None\n",
    "\n",
    "                # Check if session_data_id is None, and skip the file if it is\n",
    "                if session_data_id is not None:\n",
    "                    # Iterate over all occurrences of \"owner\" element with a value containing \"Fastball\"\n",
    "                    for owner_element in root.findall('.//owner'):\n",
    "                        if 'Fastball' in owner_element.get('value', ''):\n",
    "                            fastball_owner = owner_element\n",
    "                            # Extract and insert data into the database\n",
    "                            linear_pelvis_speed = None\n",
    "                            hss_footplant = None\n",
    "                            pelvis_ang_fp = None\n",
    "                            trunk_ang_fp = None\n",
    "                            pelvis_obl = None\n",
    "                            front_leg_brace = None\n",
    "                            front_leg_var_val = None\n",
    "                            lead_leg_midpoint = None\n",
    "                            lead_leg_grf_y = None\n",
    "                            lead_leg_grf_z = None\n",
    "                            lead_leg_grf_x = None\n",
    "                            horizontal_abduction = None\n",
    "                            shld_er_fp = None\n",
    "                            shld_er_max = None\n",
    "                            lateral_trunk_tilt = None\n",
    "                            pelvis_ang_velo = None\n",
    "                            torso_ang_velo = None\n",
    "                            arm_ang_velo = None\n",
    "                            Trunk_Ang_MER = None\n",
    "                            Trunk_Ang_Rel = None\n",
    "                            Pelvis_Ang_MER = None\n",
    "                            Pelvis_Ang_Rel = None\n",
    "                            HSS_MER = None\n",
    "                            HSS_Rel = None\n",
    "                            lead_knee_ang_at_footstrike = None\n",
    "                            Front_Leg_MER = None\n",
    "                            lead_knee_ang_at_release = None\n",
    "                            Abduction_Max = None\n",
    "                            Hand_Ang_Velo = None\n",
    "                            Stride_Length = None\n",
    "                            Arm_Slot = None\n",
    "                            weight = weight\n",
    "\n",
    "                            # Extract the value of \"owner\"\n",
    "                            pitch_value = fastball_owner.get('value', '')\n",
    "\n",
    "                            for variable_element in fastball_owner.findall('.//name[@value]'):\n",
    "                                variable_name = variable_element.attrib['value']\n",
    "                                component_x_element = variable_element.find('./component[@value=\"X\"]')\n",
    "                                component_y_element = variable_element.find('./component[@value=\"Y\"]')\n",
    "                                component_z_element = variable_element.find('./component[@value=\"Z\"]')\n",
    "\n",
    "                                if variable_name == \"MaxPelvisLinearVel_MPH\" and component_y_element is not None:\n",
    "                                    linear_pelvis_speed = float(component_y_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Hip Shoulders Sep@Footstrike\" and component_z_element is not None:\n",
    "                                    hss_footplant = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pitching_Shoulder_Angle@Release\" and component_x_element is not None:\n",
    "                                    Arm_Slot = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Hip Shoulders Sep@Max_Shoulder_Rot\" and component_z_element is not None:\n",
    "                                    HSS_MER = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Hip Shoulders Sep@Release\" and component_z_element is not None:\n",
    "                                    HSS_Rel = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pelvis_Angle@Footstrike\" and component_z_element is not None:\n",
    "                                    pelvis_ang_fp = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pelvis_Angle@Max_Shoulder_Rot\" and component_z_element is not None:\n",
    "                                    Pelvis_Ang_MER = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pelvis_Angle@Release\" and component_z_element is not None:\n",
    "                                    Pelvis_Ang_Rel = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Trunk_Angle@Footstrike\" and component_z_element is not None:\n",
    "                                    trunk_ang_fp = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Trunk_Angle@Max_Shoulder_Rot\" and component_z_element is not None:\n",
    "                                    Trunk_Ang_MER = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Trunk_Angle@Release\" and component_z_element is not None:\n",
    "                                    Trunk_Ang_Rel = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Lead_Knee_Angle@Footstrike\" and component_x_element is not None:\n",
    "                                    lead_knee_ang_at_footstrike = float(\n",
    "                                        component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                    lead_knee_ang_at_release = float(root.find(\n",
    "                                        './/name[@value=\"Lead_Knee_Angle@Release\"]/component[@value=\"X\"]').attrib[\n",
    "                                                                         'data'].replace(',', '.'))\n",
    "                                    front_leg_brace = lead_knee_ang_at_footstrike - lead_knee_ang_at_release\n",
    "                                if variable_name == \"Lead_Knee_Angle@Footstrike\" and component_y_element is not None:\n",
    "                                    lead_knee_var_val_fp = float(component_y_element.attrib['data'].replace(',', '.'))\n",
    "                                if variable_name == \"Lead_Knee_Angle@Max_Shoulder_Rot\" and component_x_element is not None:\n",
    "                                    Front_Leg_MER = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Lead_Knee_Angle@Release\" and component_y_element is not None:\n",
    "                                    lead_knee_var_val_rel = float(component_y_element.attrib['data'].replace(',', '.'))\n",
    "                                    # Calculate the difference and store in front_leg_var_val\n",
    "                                    front_leg_var_val = lead_knee_var_val_fp - lead_knee_var_val_rel\n",
    "                                if variable_name == \"Pelvis_Angle@Footstrike\" and component_y_element is not None:\n",
    "                                    pelvis_obl_fp = float(component_y_element.attrib['data'].replace(',', '.'))\n",
    "                                    pelvis_angle_release_element = root.find(\n",
    "                                        './/name[@value=\"Pelvis_Angle@Release\"]/component[@value=\"Y\"]')\n",
    "                                    if pelvis_angle_release_element is not None:\n",
    "                                        pelvis_obl_release = float(\n",
    "                                            pelvis_angle_release_element.attrib['data'].replace(',', '.'))\n",
    "                                        pelvis_obl = pelvis_obl_release - pelvis_obl_fp\n",
    "                                elif variable_name == \"Lead_Leg_GRF_mag_Midpoint_FS_Release\" and component_x_element is not None:\n",
    "                                    lead_leg_midpoint = abs(float(component_x_element.attrib['data'].replace(',', '.')))\n",
    "                                elif variable_name == \"Lead_Leg_GRF_min\" and component_y_element is not None:\n",
    "                                    lead_leg_grf_y = abs(float(component_y_element.attrib['data'].replace(',', '.')))\n",
    "                                elif variable_name == \"Lead_Leg_GRF_max\" and component_z_element is not None:\n",
    "                                    lead_leg_grf_z = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                if variable_name == \"Lead_Leg_GRF_max\" and component_x_element is not None:\n",
    "                                    lat_force_max = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Lead_Leg_GRF_min\" and component_x_element is not None:\n",
    "                                    lat_force_min = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                    # Calculate the sum of absolute values and store in lead_leg_grf_x\n",
    "                                    lead_leg_grf_x = abs(lat_force_max) + abs(lat_force_min)\n",
    "                                elif variable_name == \"Pitching_Shoulder_Angle@Footstrike\" and component_x_element is not None:\n",
    "                                    horizontal_abduction = abs(\n",
    "                                        float(component_x_element.attrib['data'].replace(',', '.')))\n",
    "                                if variable_name == \"Pitching_Shoulder_Angle@Footstrike\":\n",
    "                                    if component_z_element is not None:\n",
    "                                        shld_er_fp = float(component_z_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pitching_Shoulder_Angle_Max\" and component_z_element is not None:\n",
    "                                    shld_er_max = abs(float(component_z_element.attrib['data'].replace(',', '.')))\n",
    "                                elif variable_name == \"Pitching_Shoulder_Angle_Min\" and component_x_element is not None:\n",
    "                                    Abduction_Max = abs(float(component_x_element.attrib['data'].replace(',', '.')))\n",
    "                                elif variable_name == \"Trunk_wrt_Pelvis_FE@Release\" and component_y_element is not None:\n",
    "                                    lateral_trunk_tilt = float(component_y_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pelvis_Ang_Vel_max\" and component_x_element is not None:\n",
    "                                    pelvis_ang_velo = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Thorax_Ang_Vel_max\" and component_x_element is not None:\n",
    "                                    torso_ang_velo = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pitching_Hand_Ang_Vel_max\" and component_x_element is not None:\n",
    "                                    Hand_Ang_Velo = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pitching_Humerus_Ang_Vel_max\" and component_x_element is not None:\n",
    "                                    arm_ang_velo = float(component_x_element.attrib['data'].replace(',', '.'))\n",
    "                                elif variable_name == \"Pitching_Shoulder_Angle_Max\" and component_z_element is not None:\n",
    "                                    shld_er_max = abs(float(component_z_element.attrib['data'].replace(',', '.')))\n",
    "                                elif variable_name == \"STRIDE_LENGTH\" and component_x_element is not None:\n",
    "                                    Stride_Length = abs(float(component_x_element.attrib['data'].replace(',', '.')))\n",
    "                                \n",
    "\n",
    "                                linear_pelvis_speed = linear_pelvis_speed if linear_pelvis_speed is not None else 4\n",
    "                                hss_footplant = hss_footplant if hss_footplant is not None else 30\n",
    "                                pelvis_ang_fp = pelvis_ang_fp if pelvis_ang_fp is not None else 60\n",
    "                                trunk_ang_fp = trunk_ang_fp if trunk_ang_fp is not None else 90\n",
    "                                pelvis_obl = pelvis_obl if pelvis_obl is not None else 2\n",
    "                                front_leg_brace = front_leg_brace if front_leg_brace is not None else 8\n",
    "                                front_leg_var_val = front_leg_var_val if front_leg_var_val is not None else 0\n",
    "                                lead_leg_midpoint = lead_leg_midpoint if lead_leg_midpoint is not None else 1.5\n",
    "                                lead_leg_grf_y = lead_leg_grf_y if lead_leg_grf_y is not None else .7\n",
    "                                lead_leg_grf_z = lead_leg_grf_z if lead_leg_grf_z is not None else 1.5\n",
    "                                lead_leg_grf_x = lead_leg_grf_x if lead_leg_grf_x is not None else .25\n",
    "                                horizontal_abduction = horizontal_abduction if horizontal_abduction is not None else 20\n",
    "                                shld_er_fp = shld_er_fp if shld_er_fp is not None else 45\n",
    "                                lateral_trunk_tilt = lateral_trunk_tilt if lateral_trunk_tilt is not None else 35\n",
    "                                shld_er_max = shld_er_max if shld_er_max is not None else 160\n",
    "                                pelvis_ang_velo = pelvis_ang_velo if pelvis_ang_velo is not None else 600\n",
    "                                torso_ang_velo = torso_ang_velo if torso_ang_velo is not None else 1000\n",
    "                                arm_ang_velo = arm_ang_velo if arm_ang_velo is not None else 5000\n",
    "\n",
    "                                # Insert the data into the database\n",
    "                            cursor.execute('''\n",
    "                               INSERT INTO variables (\n",
    "                                   session_data_id,\n",
    "                                   file_name,\n",
    "                                   Pitch,\n",
    "                                   Linear_Pelvis_Speed,\n",
    "                                   HSS_Footplant,\n",
    "                                   Pelvis_Ang_Footplant,\n",
    "                                   Trunk_Ang_Footplant,\n",
    "                                   Pelvic_Obl,\n",
    "                                   Front_Leg_Brace,\n",
    "                                   Front_Leg_Var_Val,\n",
    "                                   Lead_Leg_Midpoint,\n",
    "                                   Lead_Leg_GRF_y,\n",
    "                                   Lead_Leg_GRF_z,\n",
    "                                   Lead_Leg_GRF_x,\n",
    "                                   Horizontal_Abduction,\n",
    "                                   Shld_ER_Footplant,\n",
    "                                   Shld_ER_Max,\n",
    "                                   Lateral_Trunk_Tilt,\n",
    "                                   Pelvis_Ang_Velo,\n",
    "                                   Torso_Ang_Velo,\n",
    "                                   Arm_Ang_Velo,\n",
    "                                   MPH,\n",
    "                                   Trunk_Ang_MER,\n",
    "                                   Trunk_Ang_Rel,\n",
    "                                   Pelvis_Ang_MER,\n",
    "                                   Pelvis_Ang_Rel,\n",
    "                                   HSS_MER,\n",
    "                                   HSS_Rel,\n",
    "                                   Front_Leg_Footplant,\n",
    "                                   Front_Leg_MER,\n",
    "                                   Front_Leg_Rel,\n",
    "                                   Abduction_Max,\n",
    "                                   Hand_Ang_Velo,\n",
    "                                   Stride_Length,\n",
    "                                   Arm_Slot,\n",
    "                                   Weight\n",
    "                               ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                           ''', (\n",
    "                            session_data_id, file_name, pitch_value, linear_pelvis_speed, hss_footplant, pelvis_ang_fp,\n",
    "                            trunk_ang_fp, pelvis_obl, front_leg_brace, front_leg_var_val, lead_leg_midpoint, lead_leg_grf_y,\n",
    "                            lead_leg_grf_z, lead_leg_grf_x, horizontal_abduction, shld_er_fp, shld_er_max,\n",
    "                            lateral_trunk_tilt, pelvis_ang_velo, torso_ang_velo, arm_ang_velo, None, Trunk_Ang_MER, Trunk_Ang_Rel, Pelvis_Ang_MER, Pelvis_Ang_Rel, HSS_MER, HSS_Rel, lead_knee_ang_at_footstrike, Front_Leg_MER, lead_knee_ang_at_release,Abduction_Max, Hand_Ang_Velo, Stride_Length, Arm_Slot, weight))\n",
    "\n",
    "                            # Increment the count of new data entries\n",
    "                            new_data_entries += 1\n",
    "                else:\n",
    "                    print(f\"Skipping file {file_name} due to missing session_data_id.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print the error and the file name where it occurred\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "    # Commit the changes for each file\n",
    "    conn.commit()\n",
    "\n",
    "    # If no new data entries, break out of the loop\n",
    "    if new_data_entries == 0:\n",
    "        break\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted into the database.\")\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"Cover_Page.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "directory_path = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\"\n",
    "\n",
    "# Get a list of XML files in the specified directory\n",
    "xml_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith(\".xml\")]\n",
    "\n",
    "# Track the number of new data entries\n",
    "new_data_entries = 0\n",
    "\n",
    "# Parse the XML files\n",
    "for file_name in xml_files:\n",
    "    try:\n",
    "        # Check if the file has already been processed\n",
    "        cursor.execute('SELECT COUNT(*) FROM variables WHERE file_name = ?', (file_name,))\n",
    "        count = cursor.fetchone()[0]\n",
    "\n",
    "        if count == 0:\n",
    "            # Parse the XML file\n",
    "            tree = ET.parse(file_name)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Extract session_data_id from the file name\n",
    "            session_data_id_match = re.search(r\"session_(.+)\\.xml\", file_name)\n",
    "            if session_data_id_match:\n",
    "                session_data_id = session_data_id_match.group(1)\n",
    "            else:\n",
    "                session_data_id = None\n",
    "\n",
    "            # Check if session_data_id is None, and skip the file if it is\n",
    "            if session_data_id is not None:\n",
    "                # Extract Weight\n",
    "                weight_element = root.find('./Fields/Weight')\n",
    "                weight = float(weight_element.text) if weight_element is not None else None\n",
    "\n",
    "                # Iterate over all occurrences of \"Measurement\" element\n",
    "                for measurement_element in root.findall('.//Measurement'):\n",
    "                    pitch_value = measurement_element.get('Filename')\n",
    "                    used_element = measurement_element.find('./Fields/Used')\n",
    "\n",
    "                    if pitch_value is not None and used_element is not None:\n",
    "                        # Replace \"qtm\" with \"c3d\" in pitch_value\n",
    "                        pitch_value = pitch_value.replace(\"qtm\", \"c3d\")\n",
    "\n",
    "                        # Print statement for debugging\n",
    "                        print(f\"Filename: {pitch_value}, Used: {used_element.text}\")\n",
    "\n",
    "                        if 'Fastball' in pitch_value and used_element.text == 'True':\n",
    "                            # Extract the values of \"Comments\" (MPH)\n",
    "                            comments_value_element = measurement_element.find('./Fields/Comments')\n",
    "\n",
    "                            mph_value = None\n",
    "                            if comments_value_element is not None:\n",
    "                                mph_value = float(comments_value_element.text)\n",
    "                                print(f\"MPH: {mph_value}, Weight: {weight}, Session ID: {session_data_id}\")\n",
    "\n",
    "                            # Update the MPH and Weight values in the \"variables\" table\n",
    "                            cursor.execute('''\n",
    "                                UPDATE variables\n",
    "                                SET MPH = ?, Weight = ?\n",
    "                                WHERE session_data_id = ? AND Pitch = ?\n",
    "                            ''', (mph_value, weight, session_data_id, pitch_value))\n",
    "\n",
    "                            # Increment the new data entries counter\n",
    "                            new_data_entries += 1\n",
    "                    else:\n",
    "                        print(\"Filename or Used element not found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute('SELECT id, Weight, Lead_Leg_Midpoint, Lead_Leg_GRF_y, Lead_Leg_GRF_z, Lead_Leg_GRF_x FROM variables')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    id, weight, midpoint, grf_y, grf_z, grf_x = row\n",
    "\n",
    "    # Set Weight to 195 if it is None\n",
    "    if weight is None or weight <= 0:\n",
    "        weight = 88\n",
    "\n",
    "    # Calculate the adjustment factor based on Weight\n",
    "    adjustment_factor = weight * 9.81\n",
    "\n",
    "    # Adjust values if they are above 4\n",
    "    if midpoint and midpoint > 4:\n",
    "        midpoint /= adjustment_factor\n",
    "    if grf_y and grf_y > 4:\n",
    "        grf_y /= adjustment_factor\n",
    "    if grf_z and grf_z > 4:\n",
    "        grf_z /= adjustment_factor\n",
    "    if grf_x and grf_x > 4:\n",
    "        grf_x /= adjustment_factor\n",
    "\n",
    "    # Update the database with the adjusted values\n",
    "    cursor.execute('''\n",
    "        UPDATE variables\n",
    "        SET Lead_Leg_Midpoint = ?, Lead_Leg_GRF_y = ?, Lead_Leg_GRF_z = ?, Lead_Leg_GRF_x = ?, Weight = ?\n",
    "        WHERE id = ?\n",
    "    ''', (midpoint, grf_y, grf_z, grf_x, weight, id))\n",
    "\n",
    "# Commit the adjusted values\n",
    "conn.commit()\n",
    "\n",
    "print(\"Ground reaction forces adjusted based on Weight.\")\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"Number of new data entries: {new_data_entries}\")\n",
    "print(\"Data inserted into the database.\")\n",
    "\n",
    "# Move xml files from New Data folder to appropriate folder\n",
    "# Define source directory and destination directories\n",
    "source_dir = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\"\n",
    "dest_dir_data = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\Kinematic Data\\High School\"\n",
    "dest_dir_mph = r\"C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\MPH Data\\High School\"\n",
    "\n",
    "# Ensure the destination directories exist\n",
    "os.makedirs(dest_dir_data, exist_ok=True)\n",
    "os.makedirs(dest_dir_mph, exist_ok=True)\n",
    "\n",
    "# Iterate through files in the source directory\n",
    "for file_name in os.listdir(source_dir):\n",
    "    source_file_path = os.path.join(source_dir, file_name)\n",
    "    \n",
    "    # Check if it's a file (not a directory)\n",
    "    if os.path.isfile(source_file_path):\n",
    "        if \"session_data_\" in file_name:\n",
    "            # Move file containing \"session_data_\" to the kinematic data folder\n",
    "            dest_path = os.path.join(dest_dir_data, file_name)\n",
    "            shutil.move(source_file_path, dest_path)\n",
    "            print(f\"Moved {file_name} to {dest_dir_data}\")\n",
    "        elif \"session_\" in file_name:\n",
    "            # Move file containing \"session_\" to the MPH data folder\n",
    "            dest_path = os.path.join(dest_dir_mph, file_name)\n",
    "            shutil.move(source_file_path, dest_path)\n",
    "            print(f\"Moved {file_name} to {dest_dir_mph}\")\n",
    "            \n",
    "# Generates Score\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"Cover_Page.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Select all rows from the 'variables' table\n",
    "cursor.execute('SELECT * FROM variables')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Iterate through each row and calculate the score\n",
    "for row in rows:\n",
    "    linear_pelvis_speed = row[5]\n",
    "    hss_footplant = row[6]\n",
    "    pelvis_ang_fp = row[7]\n",
    "    trunk_ang_fp = row[8]\n",
    "    pelvis_obl = row[9]\n",
    "    front_leg_brace = row[10]\n",
    "    front_leg_var_val = row[11]\n",
    "    lead_leg_midpoint = row[12]\n",
    "    lead_leg_grf_y = row[13]\n",
    "    lead_leg_grf_z = row[14]\n",
    "    lead_leg_grf_x = row[15]\n",
    "    horizontal_abduction = row[16]\n",
    "    shld_er_fp = row[17]\n",
    "    shld_er_max = row[18]\n",
    "    lateral_trunk_tilt = row[19]\n",
    "    pelvis_ang_velo = row[20]\n",
    "    torso_ang_velo = row[21]\n",
    "    arm_ang_velo = row[22]\n",
    "    MPH = row[23]\n",
    "\n",
    "    # Check for None values and replace with 0\n",
    "    linear_pelvis_speed = linear_pelvis_speed if linear_pelvis_speed is not None else 4\n",
    "    hss_footplant = hss_footplant if hss_footplant is not None else 30\n",
    "    pelvis_ang_fp = pelvis_ang_fp if pelvis_ang_fp is not None else 60\n",
    "    trunk_ang_fp = trunk_ang_fp if trunk_ang_fp is not None else 90\n",
    "    pelvis_obl = pelvis_obl if pelvis_obl is not None else 2\n",
    "    front_leg_brace = front_leg_brace if front_leg_brace is not None else 8\n",
    "    front_leg_var_val = front_leg_var_val if front_leg_var_val is not None else 0\n",
    "    lead_leg_midpoint = lead_leg_midpoint if lead_leg_midpoint is not None else 1.5\n",
    "    lead_leg_grf_y = lead_leg_grf_y if lead_leg_grf_y is not None else .7\n",
    "    lead_leg_grf_z = lead_leg_grf_z if lead_leg_grf_z is not None else 1.5\n",
    "    lead_leg_grf_x = lead_leg_grf_x if lead_leg_grf_x is not None else .25\n",
    "    horizontal_abduction = horizontal_abduction if horizontal_abduction is not None else 20\n",
    "    shld_er_fp = shld_er_fp if shld_er_fp is not None else 45\n",
    "    lateral_trunk_tilt = lateral_trunk_tilt if lateral_trunk_tilt is not None else 35\n",
    "    shld_er_max = shld_er_max if shld_er_max is not None else 160\n",
    "    pelvis_ang_velo = pelvis_ang_velo if pelvis_ang_velo is not None else 600\n",
    "    torso_ang_velo = torso_ang_velo if torso_ang_velo is not None else 1000\n",
    "    arm_ang_velo = arm_ang_velo if arm_ang_velo is not None else 5000\n",
    "    MPH = MPH if MPH is not None else 75\n",
    "\n",
    "    # Calculate the score using the specified equation\n",
    "    score = (0.05 * linear_pelvis_speed) + (0.15 * front_leg_brace) + \\\n",
    "            (5 * lead_leg_midpoint) + \\\n",
    "            (0.55 * horizontal_abduction) + (0.012 * torso_ang_velo) + (.05 * pelvis_obl) + (\n",
    "                        .6 * trunk_ang_fp) - (.45 * pelvis_ang_fp) + (.1 * shld_er_max) + (.1 * front_leg_var_val) + (\n",
    "                        .05 * pelvis_ang_velo) + MPH\n",
    "\n",
    "    # Update the 'Score' column in the database\n",
    "    cursor.execute('UPDATE variables SET Score = ? WHERE id = ?', (score, row[0]))\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Scores updated in the database.\")\n"
   ],
   "id": "9f85239ff2313529",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'session.xml' copied and renamed to: H:/Pitching/Data/Guadet, CJ 01-25\\temp_rename\\session_CJ 01-25 Guadet_01-15-25.xml\n",
      "File 'session_data.xml' copied and renamed to: H:/Pitching/Data/Guadet, CJ 01-25\\temp_rename\\session_data_CJ 01-25 Guadet_01-15-25.xml\n",
      "File 'session_CJ 01-25 Guadet_01-15-25.xml' copied to: G:\\My Drive\\Pitching Data\\New Data\\session_CJ 01-25 Guadet_01-15-25.xml\n",
      "File 'session_data_CJ 01-25 Guadet_01-15-25.xml' copied to: G:\\My Drive\\Pitching Data\\New Data\\session_data_CJ 01-25 Guadet_01-15-25.xml\n",
      "File 'session_CJ 01-25 Guadet_01-15-25.xml' moved to: C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\\session_CJ 01-25 Guadet_01-15-25.xml\n",
      "File 'session_data_CJ 01-25 Guadet_01-15-25.xml' moved to: C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\\session_data_CJ 01-25 Guadet_01-15-25.xml\n",
      "XML files copied successfully!\n",
      "Skipping file C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\\session_CJ 01-25 Guadet_01-15-25.xml due to missing session_data_id.\n",
      "Skipping file C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\New Data\\session_CJ 01-25 Guadet_01-15-25.xml due to missing session_data_id.\n",
      "Data inserted into the database.\n",
      "Filename: Fastball RH 1.c3d, Used: False\n",
      "Filename: Fastball RH 10.c3d, Used: False\n",
      "Filename: Fastball RH 11.c3d, Used: True\n",
      "MPH: 88.0, Weight: 80.285430908, Session ID: CJ 01-25 Guadet_01-15-25\n",
      "Filename: Fastball RH 12.c3d, Used: True\n",
      "MPH: 89.1, Weight: 80.285430908, Session ID: CJ 01-25 Guadet_01-15-25\n",
      "Filename: Fastball RH 13.c3d, Used: False\n",
      "Filename: Fastball RH 14.c3d, Used: False\n",
      "Filename: Fastball RH 15.c3d, Used: False\n",
      "Filename: Fastball RH 2.c3d, Used: False\n",
      "Filename: Fastball RH 3.c3d, Used: False\n",
      "Filename: Fastball RH 4.c3d, Used: False\n",
      "Filename: Fastball RH 5.c3d, Used: True\n",
      "MPH: 88.0, Weight: 80.285430908, Session ID: CJ 01-25 Guadet_01-15-25\n",
      "Filename: Fastball RH 6.c3d, Used: True\n",
      "MPH: 87.9, Weight: 80.285430908, Session ID: CJ 01-25 Guadet_01-15-25\n",
      "Filename: Fastball RH 7.c3d, Used: False\n",
      "Filename: Fastball RH 8.c3d, Used: True\n",
      "MPH: 88.7, Weight: 80.285430908, Session ID: CJ 01-25 Guadet_01-15-25\n",
      "Filename: Fastball RH 9.c3d, Used: False\n",
      "Filename: Functional hip RH 1.c3d, Used: False\n",
      "Filename: Static 1.c3d, Used: False\n",
      "Filename: Static 2.c3d, Used: True\n",
      "Ground reaction forces adjusted based on Weight.\n",
      "Number of new data entries: 5\n",
      "Data inserted into the database.\n",
      "Moved session_CJ 01-25 Guadet_01-15-25.xml to C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\MPH Data\\High School\n",
      "Moved session_data_CJ 01-25 Guadet_01-15-25.xml to C:\\Users\\q\\PycharmProjects\\Rename_Session.xml\\Pitching Data\\Kinematic Data\\High School\n",
      "Scores updated in the database.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:23:10.698738Z",
     "start_time": "2025-01-16T22:23:10.161441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Dash Board\n",
    "\n",
    "import dash\n",
    "from dash import html, dcc\n",
    "import sqlite3\n",
    "from scipy.stats import percentileofscore\n",
    "import numpy as np\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Database paths\n",
    "db_path = r\"C:/Users/q/PycharmProjects/Rename_Session.xml/Cover_Page.db\"\n",
    "db_reference_path = r\"C:/Users/q/PycharmProjects/Rename_Session.xml/grading_equation_reference_data_HS.db\"\n",
    "\n",
    "# List of columns to pull and calculate percentiles for\n",
    "columns_to_pull = [\n",
    "    \"session_data_id\", \"Front_Leg_Brace\", \"HSS_Footplant\", \"Pelvis_Ang_Footplant\", \"Trunk_Ang_Footplant\",\n",
    "    \"Horizontal_Abduction\", \"Shld_ER_Footplant\", \"Shld_ER_Max\", \"Pelvis_Ang_Velo\", \"Torso_Ang_Velo\",\n",
    "    \"Arm_Ang_Velo\", \"MPH\", \"Trunk_Ang_MER\", \"Trunk_Ang_Rel\", \"Pelvis_Ang_MER\", \"Pelvis_Ang_Rel\", \n",
    "    \"Score\", \"HSS_MER\", \"HSS_Rel\", \"Front_Leg_Footplant\", \"Front_Leg_MER\", \"Front_Leg_Rel\", \n",
    "    \"Abduction_Max\", \"Hand_Ang_Velo\"\n",
    "]\n",
    "\n",
    "# Fetch the row with the highest score\n",
    "def fetch_highest_score_row(db_path, columns):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    column_query = \", \".join(columns)\n",
    "    query = f\"SELECT {column_query} FROM variables ORDER BY Score DESC LIMIT 1;\"\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "\n",
    "    if result:\n",
    "        return {columns[i]: result[i] for i in range(len(columns))}\n",
    "    return {}\n",
    "\n",
    "def calculate_percentiles(db_reference_path, data_row, columns):\n",
    "    conn_ref = sqlite3.connect(db_reference_path)\n",
    "    cursor_ref = conn_ref.cursor()\n",
    "    percentiles = {}\n",
    "\n",
    "    for column in columns:\n",
    "        # Skip if the column does not exist or the value is None\n",
    "        if column not in data_row or data_row[column] is None:\n",
    "            percentiles[column] = None\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Ensure the current value is numeric\n",
    "            current_value = float(data_row[column])\n",
    "        except ValueError:\n",
    "            percentiles[column] = None\n",
    "            continue\n",
    "\n",
    "        cursor_ref.execute(f\"SELECT CAST({column} AS REAL) FROM variables WHERE {column} IS NOT NULL\")\n",
    "        reference_values = [row[0] for row in cursor_ref.fetchall() if row[0] is not None]\n",
    "\n",
    "        # Convert reference_values to a numeric array\n",
    "        reference_values = np.array(reference_values, dtype=np.float64)\n",
    "\n",
    "        if reference_values.size > 0:\n",
    "            percentiles[column] = percentileofscore(reference_values, current_value, kind='mean')\n",
    "        else:\n",
    "            percentiles[column] = None\n",
    "\n",
    "    conn_ref.close()\n",
    "    return percentiles\n",
    "\n",
    "\n",
    "# Fetch data and calculate percentiles\n",
    "data_row = fetch_highest_score_row(db_path, columns_to_pull)\n",
    "percentile_values = calculate_percentiles(db_reference_path, data_row, columns_to_pull)\n",
    "\n",
    "# Merge percentile data into data_row\n",
    "for key, value in percentile_values.items():\n",
    "    data_row[f\"{key}_percentile\"] = value\n",
    "\n",
    "# Helper function to create a table\n",
    "def create_table(rows, cols, col_widths, data):\n",
    "    header_row = html.Tr([\n",
    "        html.Th(col, style={'width': f\"{col_width}px\", 'height': '40px', 'fontWeight': 'normal', 'fontSize': '12px', 'padding': '4px'}) for col, col_width in zip(cols, col_widths)\n",
    "    ])\n",
    "\n",
    "    body_rows = [\n",
    "        html.Tr([\n",
    "            html.Td(data[i][j], style={\n",
    "                'width': f\"{col_widths[j]}px\", 'height': '36px', 'padding': '4px',\n",
    "                'textAlign': 'right' if j == 0 else 'center'\n",
    "            }) for j in range(len(cols))\n",
    "        ]) for i in range(rows)\n",
    "    ]\n",
    "\n",
    "    return html.Table([\n",
    "        html.Thead(header_row),\n",
    "        html.Tbody(body_rows)\n",
    "    ])\n",
    "\n",
    "def extract_name_and_date(session_data_id):\n",
    "    if session_data_id:\n",
    "        parts = session_data_id.split(\"_\")  # Split by underscore\n",
    "        name = parts[0]  # Extract name\n",
    "        raw_date = parts[1] if len(parts) > 1 else \"Unknown Date\"  # Extract date\n",
    "        # Reformat date to MM/DD/YY\n",
    "        formatted_date = raw_date.replace(\"-\", \"/\")\n",
    "        return name, formatted_date\n",
    "    return \"\", \"Unknown Date\"\n",
    "\n",
    "# Extract Name and Date from `session_data_id`\n",
    "if data_row and \"session_data_id\" in data_row:\n",
    "    name, date = extract_name_and_date(data_row[\"session_data_id\"])\n",
    "    data_row[\"Name\"] = name\n",
    "    data_row[\"Date\"] = date\n",
    "else:\n",
    "    data_row[\"Name\"] = \"Unknown Player\"\n",
    "    data_row[\"Date\"] = \"Unknown Date\"\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    # Background layer\n",
    "    html.Div(style={'backgroundColor': '#dfe0e0', 'width': '100vw', 'height': '100vh', 'position': 'absolute', 'zIndex': '-2'}),\n",
    "    \n",
    "    # Background image layer\n",
    "    html.Div(\n",
    "        style={\n",
    "            'position': 'absolute',\n",
    "            'width': '1878.5px',\n",
    "            'height': '120%',\n",
    "            'left': '35.9px',\n",
    "            'top': '173.5px',\n",
    "            'backgroundImage': 'url(\"https://8ctanebaseball.com/wp-content/uploads/2024/02/cropped-8ctaneBaseballLogo-2.png\")',\n",
    "            'backgroundSize': 'contain',\n",
    "            'backgroundRepeat': 'no-repeat',\n",
    "            'opacity': '0.15',\n",
    "            'zIndex': '-1'\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    # Player's Name\n",
    "    html.Div(data_row.get(\"Name\", \"\"), style={\n",
    "        'position': 'absolute',\n",
    "        'left': '50%',\n",
    "        'top': '40px',\n",
    "        'transform': 'translateX(-50%)',\n",
    "        'fontSize': '56px',\n",
    "        'fontFamily': 'Verdana, sans-serif',\n",
    "        'fontWeight': 'bold',\n",
    "        'textAlign': 'center'\n",
    "    }),\n",
    "    \n",
    "    # Date\n",
    "    html.Div(data_row.get(\"Date\", \"\"), style={\n",
    "        'position': 'absolute',\n",
    "        'left': '50%',\n",
    "        'top': '110px',  # Positioned below the name\n",
    "        'transform': 'translateX(-50%)',\n",
    "        'fontSize': '28px',  # Smaller font size\n",
    "        'fontFamily': 'Verdana, sans-serif',\n",
    "        'textAlign': 'center'\n",
    "    }),\n",
    "\n",
    "\n",
    "    # Lead Leg Flexion Table\n",
    "    html.Div([\n",
    "        html.H4(\"Lead Leg Flexion\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(3, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Foot Plant\", f\"{data_row['Front_Leg_Footplant']:.1f}°\", f\"{data_row.get('Front_Leg_Footplant_percentile', ''):.1f}\" if data_row.get('Front_Leg_Footplant_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['Front_Leg_MER']:.1f}°\", f\"{data_row.get('Front_Leg_MER_percentile', ''):.1f}\" if data_row.get('Front_Leg_MER_percentile') else \"\"],\n",
    "            [\"Release\", f\"{data_row['Front_Leg_Rel']:.1f}°\", f\"{data_row.get('Front_Leg_Rel_percentile', ''):.1f}\" if data_row.get('Front_Leg_Rel_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '79px', 'top': '70px'}),\n",
    "\n",
    "    # Trunk Position Table\n",
    "    html.Div([\n",
    "        html.H4(\"Trunk Position\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(3, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Counter Rotation at FP\", f\"{data_row['Trunk_Ang_Footplant']:.1f}°\",\n",
    "             f\"{data_row.get('Trunk_Ang_Footplant_percentile', ''):.1f}\" if data_row.get('Trunk_Ang_Footplant_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['Trunk_Ang_MER']:.1f}°\",\n",
    "             f\"{data_row.get('Trunk_Ang_MER_percentile', ''):.1f}\" if data_row.get('Trunk_Ang_MER_percentile') else \"\"],\n",
    "            [\"Release\", f\"{data_row['Trunk_Ang_Rel']:.1f}°\",\n",
    "             f\"{data_row.get('Trunk_Ang_Rel_percentile', ''):.1f}\" if data_row.get('Trunk_Ang_Rel_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '79px', 'top': '290px'}),\n",
    "    \n",
    "    # Pelvis Rotation Table\n",
    "    html.Div([\n",
    "        html.H4(\"Pelvis Rotation\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(3, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Position at Foot Plant\", f\"{data_row['Pelvis_Ang_Footplant']:.1f}°\",\n",
    "             f\"{data_row.get('Pelvis_Ang_Footplant_percentile', ''):.1f}\" if data_row.get('Pelvis_Ang_Footplant_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['Pelvis_Ang_MER']:.1f}°\",\n",
    "             f\"{data_row.get('Pelvis_Ang_MER_percentile', ''):.1f}\" if data_row.get('Pelvis_Ang_MER_percentile') else \"\"],\n",
    "            [\"Release\", f\"{data_row['Pelvis_Ang_Rel']:.1f}°\",\n",
    "             f\"{data_row.get('Pelvis_Ang_Rel_percentile', ''):.1f}\" if data_row.get('Pelvis_Ang_Rel_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '79px', 'top': '510px'}),\n",
    "    \n",
    "    # Hip-Shoulder Separation Table\n",
    "    html.Div([\n",
    "        html.H4(\"Hip-Shoulder Separation\", style={'textAlign': 'left', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(3, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Foot Plant\", f\"{data_row['HSS_Footplant']:.1f}°\",\n",
    "             f\"{data_row.get('HSS_Footplant_percentile', ''):.1f}\" if data_row.get('HSS_Footplant_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['HSS_MER']:.1f}°\",\n",
    "             f\"{data_row.get('HSS_MER_percentile', ''):.1f}\" if data_row.get('HSS_MER_percentile') else \"\"],\n",
    "            [\"Release\", f\"{data_row['HSS_Rel']:.1f}°\",\n",
    "             f\"{data_row.get('HSS_Rel_percentile', ''):.1f}\" if data_row.get('HSS_Rel_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '79px', 'top': '730px'}),\n",
    "    \n",
    "    # Shoulder ER Table\n",
    "    html.Div([\n",
    "        html.H4(\"Shoulder ER\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(2, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"External Rotation at FP\", f\"{data_row['Shld_ER_Footplant']:.1f}°\",\n",
    "             f\"{data_row.get('Shld_ER_Footplant_percentile', ''):.1f}\" if data_row.get('Shld_ER_Footplant_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['Shld_ER_Max']:.1f}°\",\n",
    "             f\"{data_row.get('Shld_ER_Max_percentile', ''):.1f}\" if data_row.get('Shld_ER_Max_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '615px', 'top': '778px'}),\n",
    "    \n",
    "    # Abduction Table\n",
    "    html.Div([\n",
    "        html.H4(\"Abduction\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(2, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Horizontal Abduction\", f\"{data_row['Horizontal_Abduction']:.1f}°\",\n",
    "             f\"{data_row.get('Horizontal_Abduction_percentile', ''):.1f}\" if data_row.get('Horizontal_Abduction_percentile') else \"\"],\n",
    "            [\"Max External Rotation\", f\"{data_row['Abduction_Max']:.1f}°\",\n",
    "             f\"{data_row.get('Abduction_Max_percentile', ''):.1f}\" if data_row.get('Abduction_Max_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '1112px', 'top': '778px'}),\n",
    "    \n",
    "    # Kinematic Sequence Table\n",
    "    html.Div([\n",
    "        html.H4(\"Kinematic Sequence\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(4, [\"\", \"Value\", \"Percentile\"], [169, 69, 69], [\n",
    "            [\"Arm Angular Velo\", f\"{data_row['Arm_Ang_Velo']:.0f}°/sec\",\n",
    "             f\"{data_row.get('Arm_Ang_Velo_percentile', ''):.1f}\" if data_row.get('Arm_Ang_Velo_percentile') else \"\"],\n",
    "            [\"Hand Angular Velo\", f\"{data_row['Hand_Ang_Velo']:.0f}°/sec\",\n",
    "             f\"{data_row.get('Hand_Ang_Velo_percentile', ''):.1f}\" if data_row.get('Hand_Ang_Velo_percentile') else \"\"],\n",
    "            [\"Pelvis Angular Velo\", f\"{data_row['Pelvis_Ang_Velo']:.0f}°/sec\",\n",
    "             f\"{data_row.get('Pelvis_Ang_Velo_percentile', ''):.1f}\" if data_row.get('Pelvis_Ang_Velo_percentile') else \"\"],\n",
    "            [\"Torso Angular Velo\", f\"{data_row['Torso_Ang_Velo']:.0f}°/sec\",\n",
    "             f\"{data_row.get('Torso_Ang_Velo_percentile', ''):.1f}\" if data_row.get('Torso_Ang_Velo_percentile') else \"\"]\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '1592px', 'top': '118px'}),\n",
    "    \n",
    "    # Trackman Metrics Table\n",
    "    html.Div([\n",
    "        html.H4(\"Trackman Metrics\", style={'textAlign': 'center', 'marginBottom': '-13px', 'fontFamily': 'Verdana, sans-serif'}),\n",
    "        create_table(8, [\"\", \"Average\", \"Max\"], [169, 69, 69],\n",
    "                     [[\"Velocity\", \"\", \"\"],\n",
    "                      [\"Spin Rate\", \"\", \"\"],\n",
    "                      [\"Horizontal Break\", \"\", \"\"],\n",
    "                      [\"Induced Vertical Break\", \"\", \"\"],\n",
    "                      [\"Release Height\", \"\", \"\"],\n",
    "                      [\"Release Side\", \"\", \"\"],\n",
    "                      [\"VAA\", \"\", \"\"],\n",
    "                      [\"HAA\", \"\", \"\"]])\n",
    "    ], style={'position': 'absolute', 'left': '1592px', 'top': '468px'}),\n",
    "    \n",
    "    # Score Table\n",
    "    html.Div([\n",
    "        html.Table([\n",
    "            html.Tbody([\n",
    "                html.Tr([\n",
    "                    html.Td(\"Score\", style={\n",
    "                        'fontWeight': 'bold', 'fontSize': '24px', 'fontFamily': 'Verdana, sans-serif',\n",
    "                        'textAlign': 'center', 'width': '169px', 'height': '36px', 'padding': '4px'\n",
    "                    }),\n",
    "                    html.Td(f\"{data_row['Score']:.1f}\" if 'Score' in data_row else \"N/A\", style={\n",
    "                        'fontWeight': 'bold', 'fontSize': '24px', 'fontFamily': 'Verdana, sans-serif',\n",
    "                        'textAlign': 'center', 'width': '69px', 'height': '36px', 'padding': '4px'\n",
    "                    })\n",
    "                ]),\n",
    "                html.Tr([\n",
    "                    html.Td(\"Percentile\", style={\n",
    "                        'textAlign': 'center', 'fontFamily': 'Verdana, sans-serif',\n",
    "                        'width': '169px', 'height': '36px', 'padding': '4px'\n",
    "                    }),\n",
    "                    html.Td(\n",
    "                        f\"{data_row.get('Score_percentile', ''):.1f}\" if data_row.get('Score_percentile') is not None else \"\",\n",
    "                        style={\n",
    "                            'textAlign': 'center', 'fontFamily': 'Verdana, sans-serif',\n",
    "                            'width': '69px', 'height': '36px', 'padding': '4px'\n",
    "                        }\n",
    "                    )\n",
    "                ])\n",
    "            ])\n",
    "        ])\n",
    "    ], style={'position': 'absolute', 'left': '893px', 'top': '628px'}),\n",
    "\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, host='127.0.0.1', port=8051)\n"
   ],
   "id": "89e0de8a41517eec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1da72327920>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:23:15.727726Z",
     "start_time": "2025-01-16T22:23:15.686466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# File paths\n",
    "db_path = \"Cover_Page.db\"  # Path to your SQLite database\n",
    "excel_path = \"Metric Outputs3.xlsx\"  # Path to your Excel mapping file\n",
    "output_json_path = \"output_payload.json\"  # Path to save the output JSON\n",
    "\n",
    "# Load the Excel file\n",
    "mapping_df = pd.read_excel(excel_path)\n",
    "\n",
    "# Extract the list of required columns from the database (Column A in Excel)\n",
    "required_columns = mapping_df[\"originColumn\"].dropna().tolist()\n",
    "\n",
    "# Ensure \"Score\" is in the required columns to retrieve it for filtering\n",
    "if \"Score\" not in required_columns:\n",
    "    required_columns.append(\"Score\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Get valid column names from the database\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"PRAGMA table_info(variables);\")\n",
    "valid_columns = {col[1] for col in cursor.fetchall()}\n",
    "\n",
    "# Filter out invalid or problematic column names\n",
    "filtered_columns = [col for col in required_columns if col in valid_columns]\n",
    "\n",
    "# Query the database for the filtered columns\n",
    "query = f\"SELECT {', '.join(filtered_columns)} FROM variables\"\n",
    "db_data = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Identify the row with the highest Score\n",
    "if \"Score\" in db_data.columns:\n",
    "    max_score_row = db_data.loc[db_data[\"Score\"].idxmax()]\n",
    "else:\n",
    "    raise ValueError(\"The 'Score' column is not present in the database or the mapping file.\")\n",
    "\n",
    "# Initialize the JSON payload\n",
    "payload = {\n",
    "    \"athleteUuid\": \"\",\n",
    "    \"level\": \"HIGH_SCHOOL\",\n",
    "    \"score\": max_score_row[\"Score\"],  # Use the score from the row with the highest score\n",
    "    \"metrics\": []\n",
    "}\n",
    "\n",
    "# Iterate through the mapping file and populate metrics for the row with the highest score\n",
    "for _, map_row in mapping_df.iterrows():\n",
    "    column = map_row[\"originColumn\"]\n",
    "    if column in max_score_row:\n",
    "        metric_entry = {\n",
    "            \"category\": map_row[\"category\"],\n",
    "            \"name\": map_row[\"name\"],\n",
    "            \"value\": max_score_row[column],\n",
    "            \"valueUnit\": map_row[\"valueUnit\"],\n",
    "            \"orientation\": map_row[\"orientation\"] if pd.notna(map_row[\"orientation\"]) else None,\n",
    "        }\n",
    "        payload[\"metrics\"].append(metric_entry)\n",
    "\n",
    "# Save the JSON payload to a file\n",
    "with open(output_json_path, \"w\") as json_file:\n",
    "    json.dump(payload, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON payload saved to {output_json_path}\")\n"
   ],
   "id": "b7ad84e5c3dce8af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON payload saved to output_payload.json\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:10:20.996958Z",
     "start_time": "2025-01-16T22:10:20.974276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates JSON files based on schema for entire database (HS, College, Pro) \n",
    "# \n",
    "# import pandas as pd\n",
    "# import sqlite3\n",
    "# import json\n",
    "# \n",
    "# # File paths\n",
    "# metrics_mapping_path = \"Metric Outputs3.xlsx\"  # Path to your Excel mapping file\n",
    "# grading_db_path = \"grading_equation_reference_data_HS.db\"  # Path to the SQLite database\n",
    "# output_json_path = \"athlete_reports.json\"  # Path to save the output JSON\n",
    "# \n",
    "# # Load the Excel mapping file\n",
    "# mapping_df = pd.read_excel(metrics_mapping_path)\n",
    "# \n",
    "# # Extract the list of required columns from the mapping (Column A in Excel)\n",
    "# required_columns = mapping_df[\"originColumn\"].dropna().tolist()\n",
    "# \n",
    "# # Connect to the SQLite database\n",
    "# conn = sqlite3.connect(grading_db_path)\n",
    "# \n",
    "# # Fetch valid column names from the database\n",
    "# cursor = conn.cursor()\n",
    "# cursor.execute(\"PRAGMA table_info(variables);\")\n",
    "# valid_columns = {col[1] for col in cursor.fetchall()}  # Column names from the database\n",
    "# \n",
    "# # Filter required columns to include only valid column names\n",
    "# filtered_columns = [col for col in required_columns if col in valid_columns]\n",
    "# \n",
    "# # Query the database with valid column names\n",
    "# query = f\"SELECT {', '.join(filtered_columns)} FROM variables\"\n",
    "# data = pd.read_sql_query(query, conn)\n",
    "# \n",
    "# # Close the database connection\n",
    "# conn.close()\n",
    "# \n",
    "# # Replace NaN values with 0\n",
    "# data = data.fillna(0)\n",
    "# \n",
    "# # Initialize the JSON payload\n",
    "# payload = {\n",
    "#     \"level\": \"PRO\",\n",
    "#     \"athleteReports\": []\n",
    "# }\n",
    "# \n",
    "# # Generate the athlete reports\n",
    "# for _, row in data.iterrows():\n",
    "#     athlete_report = {\n",
    "#         \"score\": row[\"Score\"],  # Ensure \"Score\" is included in the queried columns\n",
    "#         \"metrics\": []\n",
    "#     }\n",
    "#     \n",
    "#     for _, map_row in mapping_df.iterrows():\n",
    "#         origin_column = map_row[\"originColumn\"]\n",
    "#         if origin_column in row:\n",
    "#             metric_entry = {\n",
    "#                 \"category\": map_row[\"category\"],\n",
    "#                 \"name\": map_row[\"name\"],\n",
    "#                 \"value\": row[origin_column],\n",
    "#                 \"valueUnit\": map_row[\"valueUnit\"],\n",
    "#                 \"orientation\": map_row[\"orientation\"] if pd.notna(map_row[\"orientation\"]) else None,\n",
    "#             }\n",
    "#             athlete_report[\"metrics\"].append(metric_entry)\n",
    "#     \n",
    "#     payload[\"athleteReports\"].append(athlete_report)\n",
    "# \n",
    "# # Save the JSON payload to a file\n",
    "# with open(output_json_path, \"w\") as json_file:\n",
    "#     json.dump(payload, json_file, indent=4)\n",
    "# \n",
    "# print(f\"JSON payload saved to {output_json_path}\")\n"
   ],
   "id": "321a72348f404f6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T22:10:21.003785Z",
     "start_time": "2025-01-16T22:10:20.997969Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9be761e27c526fae",
   "outputs": [],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
