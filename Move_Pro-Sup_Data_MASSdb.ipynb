{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:55.472834Z",
     "start_time": "2025-01-09T16:42:49.324755Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "# Ask user to select folder containing the Session XML file\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "selected_folder = filedialog.askdirectory(initialdir='D:/Pro-Sup Test/Data/')\n",
    "if not selected_folder:\n",
    "    raise ValueError(\"No folder was selected.\")\n",
    "\n",
    "# Extract the test_date from the selected folder name\n",
    "folder_name = os.path.basename(selected_folder)\n",
    "test_date = folder_name.split('_', 1)[0]  # Extract '2024-08-13' from '2024-08-13_105_Growth Plate_'\n",
    "\n",
    "# Find the XML file titled \"Session\" in the selected folder\n",
    "xml_file_path = ''\n",
    "for r, dirs, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "            xml_file_path = os.path.join(r, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    raise FileNotFoundError(\"No 'Session' XML file found in the selected folder.\")\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(xml_file_path)\n",
    "root_xml = tree.getroot()\n",
    "\n",
    "# Extract required fields from XML\n",
    "name = root_xml.find(\".//Name\").text\n",
    "dob = root_xml.find(\".//DOB\").text\n",
    "height = root_xml.find(\".//Height\").text\n",
    "weight = root_xml.find(\".//Weight\").text\n",
    "injury_history = root_xml.find(\".//Injury_History\").text\n",
    "season_phase = root_xml.find(\".//Season_Phase\").text\n",
    "dynomometer_score = root_xml.find(\".//Dynomometer_Score\").text\n",
    "comments = root_xml.find(\".//Comments\").text\n",
    "\n",
    "# Calculate age from DOB\n",
    "dob_date = datetime.strptime(dob, \"%Y-%m-%d\")\n",
    "today = datetime.today()\n",
    "age = today.year - dob_date.year - ((today.month, today.day) < (dob_date.month, dob_date.day))\n",
    "\n",
    "# Define final columns\n",
    "final_columns = [\n",
    "    'name', 'test_date', 'age', 'height', 'weight', 'injury_history', 'season_phase', 'dynomometer_score', 'comments',\n",
    "    'forearm_rom_0to10', 'forearm_rom_10to20', 'forearm_rom_20to30', 'forearm_rom',\n",
    "    'tot_rom_0to10', 'tot_rom_10to20', 'tot_rom_20to30', 'tot_rom',\n",
    "    'num_of_flips_0_10', 'num_of_flips_10_20', 'num_of_flips_20_30', 'num_of_flips',\n",
    "    'avg_velo_0_10', 'avg_velo_10_20', 'avg_velo_20_30', 'avg_velo'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with XML data and NULL for ASCII columns\n",
    "data = {\n",
    "    'name': name,\n",
    "    'test_date': test_date,\n",
    "    'age': age,\n",
    "    'height': height,\n",
    "    'weight': weight,\n",
    "    'injury_history': injury_history,\n",
    "    'season_phase': season_phase,\n",
    "    'dynomometer_score': dynomometer_score,\n",
    "    'comments': comments,\n",
    "    'forearm_rom_0to10': None,\n",
    "    'forearm_rom_10to20': None,\n",
    "    'forearm_rom_20to30': None,\n",
    "    'forearm_rom': None,\n",
    "    'tot_rom_0to10': None,\n",
    "    'tot_rom_10to20': None,\n",
    "    'tot_rom_20to30': None,\n",
    "    'tot_rom': None,\n",
    "    'num_of_flips_0_10': None,\n",
    "    'num_of_flips_10_20': None,\n",
    "    'num_of_flips_20_30': None,\n",
    "    'num_of_flips': None,\n",
    "    'avg_velo_0_10': None,\n",
    "    'avg_velo_10_20': None,\n",
    "    'avg_velo_20_30': None,\n",
    "    'avg_velo': None\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([data], columns=final_columns)\n",
    "\n",
    "# Connect to the SQLite database and create table if needed\n",
    "db_path = 'D:/Pro-Sup Test/pro-sup_data.sqlite'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Ensure table exists\n",
    "df.head(0).to_sql('pro_sup_data', conn, if_exists='append', index=False)\n",
    "\n",
    "# Insert the row with XML data and NULL ASCII columns\n",
    "df.to_sql('pro_sup_data', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# In the cell that pulls the XML/ASCII\n",
    "global NEW_NAME, NEW_TEST_DATE\n",
    "NEW_NAME = root_xml.find(\".//Name\").text\n",
    "NEW_TEST_DATE = folder_name.split('_', 1)[0]\n",
    "\n",
    "print(\"Globals set:\", NEW_NAME, NEW_TEST_DATE)\n",
    "\n",
    "print(f\"XML data inserted for {name} with test date {test_date}.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data inserted for Parnell, Josh with test date 2025-01-08.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:55.512697Z",
     "start_time": "2025-01-09T16:42:55.473381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def extract_test_date_from_ascii(ascii_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the test date in 'YYYY-MM-DD' format from the first file path in the ASCII file.\n",
    "    \n",
    "    Args:\n",
    "        ascii_file_path (str): Path to the ASCII file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted test date in 'YYYY-MM-DD' format.\n",
    "    \"\"\"\n",
    "    with open(ascii_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        # Extract the first file path\n",
    "        first_file_path = lines[0].strip().split('\\t')[0]\n",
    "        # Split the path to navigate the folder structure\n",
    "        parts = first_file_path.split('\\\\')  # Split by folder structure\n",
    "        if len(parts) > 4:  # Ensure we have enough subfolders\n",
    "            date_folder = parts[4]  # Get the folder containing the date\n",
    "            # Use regex to extract 'YYYY-MM-DD' format\n",
    "            match = re.match(r'^\\d{4}-\\d{2}-\\d{2}', date_folder)\n",
    "            if match:\n",
    "                return match.group(0)  # Return the matched date\n",
    "            else:\n",
    "                raise ValueError(f\"Unable to extract test date from folder: {date_folder}\")\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected file path structure: Unable to extract test date.\")\n",
    "\n",
    "\n",
    "# Path to ASCII file\n",
    "text_file_path = 'D:/Pro-Sup Test/pro-sup_data.txt'\n",
    "\n",
    "# Dynamically extract the test date from the ASCII file\n",
    "test_date = extract_test_date_from_ascii(text_file_path)\n",
    "print(f\"Extracted test date: {test_date}\")\n",
    "\n",
    "with open(text_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    data = [line.strip().split('\\t') for line in lines]\n",
    "\n",
    "# Extract header and data rows\n",
    "header = data[1]\n",
    "df_data = [row[1:] for row in data[5:]]\n",
    "df_ascii = pd.DataFrame(df_data, columns=header)\n",
    "\n",
    "# Replace hyphens with underscores\n",
    "df_ascii.columns = [col.replace('-', '_') for col in df_ascii.columns]\n",
    "\n",
    "row_ascii = df_ascii.iloc[0]\n",
    "\n",
    "# Extract ASCII data\n",
    "values = {col: row_ascii.get(col) for col in df_ascii.columns}\n",
    "\n",
    "# Construct the UPDATE statement\n",
    "set_clause = \", \".join([f\"{col} = ?\" for col in values.keys()])\n",
    "params = list(values.values()) + [name, test_date]\n",
    "\n",
    "update_sql = f\"UPDATE pro_sup_data SET {set_clause} WHERE name = ? AND test_date = ?;\"\n",
    "\n",
    "conn = sqlite3.connect('D:/Pro-Sup Test/pro-sup_data.sqlite')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(update_sql, params)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"ASCII data updated for {name} on test date {test_date}.\")\n",
    "\n",
    "ascii_file_path = 'D:/Pro-Sup Test/pro-sup_data.txt'\n",
    "test_date = extract_test_date_from_ascii(ascii_file_path)\n",
    "print(f\"Extracted test date: {test_date}\")\n"
   ],
   "id": "6774779f4dcc6aaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted test date: 2025-01-08\n",
      "ASCII data updated for Parnell, Josh on test date 2025-01-08.\n",
      "Extracted test date: 2025-01-08\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T22:02:57.446714Z",
     "start_time": "2025-01-09T22:02:47.798707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "# Replace these with the actual name and test_date\n",
    "# for the participant you just inserted.\n",
    "# (Or dynamically pass them in from your other script.)\n",
    "NEW_PARTICIPANT_NAME = \"John Doe\"\n",
    "NEW_PARTICIPANT_TEST_DATE = \"2024-08-13\"\n",
    "\n",
    "# Path to your SQLite database\n",
    "DB_PATH = \"D:/Pro-Sup Test/pro-sup_data.sqlite\"\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "def get_database_df(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Pull all data from the pro_sup_data table.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM pro_sup_data\", conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def build_comparison_figure(name, test_date):\n",
    "    \"\"\"\n",
    "    Build a Plotly figure comparing the newly inserted participant's\n",
    "    data to the rest of the participants' data, focusing on columns\n",
    "    containing 'tot_rom_', 'forearm_rom_', and 'num_of_flips_'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read everything from the DB\n",
    "    df = get_database_df(DB_PATH)\n",
    "\n",
    "    # Identify columns of interest\n",
    "    columns_of_interest = [\n",
    "        col for col in df.columns \n",
    "        if (\"tot_rom_\" in col) or (\"forearm_rom_\" in col) or (\"num_of_flips_\" in col)\n",
    "    ]\n",
    "\n",
    "    # Separate the newly inserted row from the rest\n",
    "    df_new = df[(df[\"name\"] == name) & (df[\"test_date\"] == test_date)]\n",
    "    df_others = df[(df[\"name\"] != name) | (df[\"test_date\"] != test_date)]\n",
    "\n",
    "    # If for some reason there is more than one new row, just take the first\n",
    "    if len(df_new) == 0:\n",
    "        raise ValueError(f\"No matching row found for name={name} and test_date={test_date}.\")\n",
    "    if len(df_new) > 1:\n",
    "        df_new = df_new.iloc[[0]]\n",
    "\n",
    "    # Convert columns to numeric (in case they are stored as strings)\n",
    "    for c in columns_of_interest:\n",
    "        df_new[c] = pd.to_numeric(df_new[c], errors='coerce')\n",
    "        df_others[c] = pd.to_numeric(df_others[c], errors='coerce')\n",
    "\n",
    "    # Extract the new participant's values as a list\n",
    "    new_values = [df_new.iloc[0][col] for col in columns_of_interest]\n",
    "\n",
    "    # Compute the mean of all other participants for each column\n",
    "    others_means = [df_others[col].mean() for col in columns_of_interest]\n",
    "\n",
    "    # Build a small DataFrame for plotting\n",
    "    plot_df = pd.DataFrame({\n",
    "        \"Column\": columns_of_interest * 2,\n",
    "        \"Value\": new_values + others_means,\n",
    "        \"Group\": [\"New Participant\"] * len(columns_of_interest) + [\"Others (Avg)\"] * len(columns_of_interest)\n",
    "    })\n",
    "\n",
    "    # Create a grouped bar chart\n",
    "    fig = px.bar(\n",
    "        plot_df, \n",
    "        x=\"Column\", \n",
    "        y=\"Value\", \n",
    "        color=\"Group\", \n",
    "        barmode=\"group\", \n",
    "        title=f\"Comparison for {name} ({test_date})\"\n",
    "    )\n",
    "    fig.update_layout(xaxis_title=\"Column of Interest\", yaxis_title=\"Value\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Build layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Pro-Sup Data Comparison Report\"),\n",
    "    dcc.Graph(id=\"comparison-graph\")\n",
    "])\n",
    "\n",
    "# Use a simple callback or just build the figure once\n",
    "@app.callback(\n",
    "    dash.dependencies.Output(\"comparison-graph\", \"figure\"),\n",
    "    [dash.dependencies.Input(\"comparison-graph\", \"id\")]  # Dummy input to trigger once\n",
    ")\n",
    "def update_graph(_):\n",
    "    return build_comparison_figure(\n",
    "        name=NEW_PARTICIPANT_NAME,\n",
    "        test_date=NEW_PARTICIPANT_TEST_DATE\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run in debug mode. Access it at http://127.0.0.1:8052\n",
    "    app.run_server(debug=True)\n"
   ],
   "id": "f147fec42517b986",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 104\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m build_comparison_figure(\n\u001B[0;32m     98\u001B[0m         name\u001B[38;5;241m=\u001B[39mNEW_PARTICIPANT_NAME,\n\u001B[0;32m     99\u001B[0m         test_date\u001B[38;5;241m=\u001B[39mNEW_PARTICIPANT_TEST_DATE\n\u001B[0;32m    100\u001B[0m     )\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;66;03m# Run in debug mode. Access it at http://127.0.0.1:8052\u001B[39;00m\n\u001B[1;32m--> 104\u001B[0m     \u001B[43mapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\dash\\dash.py:2287\u001B[0m, in \u001B[0;36mDash.run_server\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2277\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"`run_server` is a deprecated alias of `run` and may be removed in a\u001B[39;00m\n\u001B[0;32m   2278\u001B[0m \u001B[38;5;124;03mfuture version. We recommend using `app.run` instead.\u001B[39;00m\n\u001B[0;32m   2279\u001B[0m \n\u001B[0;32m   2280\u001B[0m \u001B[38;5;124;03mSee `app.run` for usage information.\u001B[39;00m\n\u001B[0;32m   2281\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2282\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2283\u001B[0m     \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m(\n\u001B[0;32m   2284\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDash.run_server is deprecated and will be removed in Dash 3.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2285\u001B[0m     )\n\u001B[0;32m   2286\u001B[0m )\n\u001B[1;32m-> 2287\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\dash\\dash.py:2173\u001B[0m, in \u001B[0;36mDash.run\u001B[1;34m(self, host, port, proxy, debug, jupyter_mode, jupyter_width, jupyter_height, jupyter_server_url, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_prune_errors, **flask_run_options)\u001B[0m\n\u001B[0;32m   2170\u001B[0m             extra_files\u001B[38;5;241m.\u001B[39mappend(path)\n\u001B[0;32m   2172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m jupyter_dash\u001B[38;5;241m.\u001B[39mactive:\n\u001B[1;32m-> 2173\u001B[0m     \u001B[43mjupyter_dash\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_app\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2174\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjupyter_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwidth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjupyter_width\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjupyter_height\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjupyter_server_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2181\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2183\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mrun(host\u001B[38;5;241m=\u001B[39mhost, port\u001B[38;5;241m=\u001B[39mport, debug\u001B[38;5;241m=\u001B[39mdebug, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mflask_run_options)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\dash\\_jupyter.py:405\u001B[0m, in \u001B[0;36mJupyterDash.run_app\u001B[1;34m(self, app, mode, width, height, host, port, server_url)\u001B[0m\n\u001B[0;32m    403\u001B[0m     display(HTML(msg))\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 405\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_error\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\dash\\_jupyter.py:392\u001B[0m, in \u001B[0;36mJupyterDash.run_app\u001B[1;34m(self, app, mode, width, height, host, port, server_url)\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    391\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 392\u001B[0m     \u001B[43mwait_for_app\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    394\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_colab:\n\u001B[0;32m    395\u001B[0m         JupyterDash\u001B[38;5;241m.\u001B[39m_display_in_colab(dashboard_url, port, mode, width, height)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\retrying.py:56\u001B[0m, in \u001B[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;129m@six\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mRetrying\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdkw\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\retrying.py:266\u001B[0m, in \u001B[0;36mRetrying.call\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop(attempt_number, delay_since_first_attempt_ms):\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_exception \u001B[38;5;129;01mand\u001B[39;00m attempt\u001B[38;5;241m.\u001B[39mhas_exception:\n\u001B[0;32m    265\u001B[0m         \u001B[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mattempt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RetryError(attempt)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\retrying.py:301\u001B[0m, in \u001B[0;36mAttempt.get\u001B[1;34m(self, wrap_exception)\u001B[0m\n\u001B[0;32m    299\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m RetryError(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 301\u001B[0m         \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\six.py:719\u001B[0m, in \u001B[0;36mreraise\u001B[1;34m(tp, value, tb)\u001B[0m\n\u001B[0;32m    717\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[0;32m    718\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[1;32m--> 719\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\n\u001B[0;32m    720\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    721\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\retrying.py:251\u001B[0m, in \u001B[0;36mRetrying.call\u001B[1;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_before_attempts(attempt_number)\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 251\u001B[0m     attempt \u001B[38;5;241m=\u001B[39m Attempt(\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, attempt_number, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m    253\u001B[0m     tb \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Rename_Session.xml\\venv\\Lib\\site-packages\\dash\\_jupyter.py:383\u001B[0m, in \u001B[0;36mJupyterDash.run_app.<locals>.wait_for_app\u001B[1;34m()\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAlive\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    382\u001B[0m         url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp://\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mport\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 383\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m    384\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAddress \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m already in use.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    385\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    Try passing a different port to run_server.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    386\u001B[0m         )\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mConnectionError \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    388\u001B[0m     _get_error()\n",
      "\u001B[1;31mOSError\u001B[0m: Address 'http://127.0.0.1:8050' already in use.\n    Try passing a different port to run_server."
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: pro_sup_data\n",
      "Table 'pro_sup_data' reordered successfully.\n",
      "All tables processed.\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "# Reorders the database to be in alphabetical order\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "db_path = \"D:/Pro-Sup Test/pro-sup_data.sqlite\" \n",
    "sort_column = \"name\"     \n",
    "\n",
    "def reorder_all_tables(db_path, sort_column):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Fetch all table names in the database\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "\n",
    "            # Skip system tables like sqlite_sequence\n",
    "            if table_name.startswith(\"sqlite_\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            # Check if the column exists in the current table\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = [info[1] for info in cursor.fetchall()]\n",
    "            if sort_column not in columns:\n",
    "                print(f\"Skipping table '{table_name}' - Column '{sort_column}' not found.\")\n",
    "                continue\n",
    "\n",
    "            # Create a new sorted table\n",
    "            temp_table = f\"{table_name}_sorted\"\n",
    "            cursor.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM {table_name} ORDER BY {sort_column} ASC;\")\n",
    "            \n",
    "            # Drop the old table\n",
    "            cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "            \n",
    "            # Rename the new table to the original name\n",
    "            cursor.execute(f\"ALTER TABLE {temp_table} RENAME TO {table_name};\")\n",
    "            print(f\"Table '{table_name}' reordered successfully.\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "        print(\"All tables processed.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "reorder_all_tables(db_path, sort_column)\n"
   ],
   "id": "24f6ebe318f5ef04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ef4ba9542b861ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
