{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T23:36:42.541138Z",
     "start_time": "2024-09-11T23:36:34.435813Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:\\\\Users\\\\q\\\\Downloads\\\\WF data3.csv'  # Adjust based on your local path\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Define the target columns, including the correct number of columns for each variable with _X, _Y, _Z\n",
    "# Updated Lead_Leg_GRF_Mag@Max_Shoulder_Rot to have only _X and no _Y, _Z\n",
    "target_columns = [\n",
    "    \"Lead_Leg_GRF_mag_max_X\", \"Lead_Leg_GRF_mag_max_Y\", \"Lead_Leg_GRF_mag_max_Z\",\n",
    "    \"Lead_Leg_GRF_max_X\", \"Lead_Leg_GRF_max_Y\", \"Lead_Leg_GRF_max_Z\",\n",
    "    \"Lead_Leg_GRF_min_X\", \"Lead_Leg_GRF_min_Y\", \"Lead_Leg_GRF_min_Z\",\n",
    "    \"Lead_Leg_GRF_mag_Midpoint_FS_Release_X\", \"Lead_Leg_GRF_mag_Midpoint_FS_Release_Y\", \"Lead_Leg_GRF_mag_Midpoint_FS_Release_Z\",\n",
    "    \"Lead_Leg_GRF@Midpoint_FS_Release_X\", \"Lead_Leg_GRF@Midpoint_FS_Release_Y\", \"Lead_Leg_GRF@Midpoint_FS_Release_Z\",\n",
    "    \"Lead_Leg_GRF@Max_Shoulder_Rot_X\", \"Lead_Leg_GRF@Max_Shoulder_Rot_Y\", \"Lead_Leg_GRF@Max_Shoulder_Rot_Z\",\n",
    "    \"Lead_Leg_GRF_Mag@Max_Shoulder_Rot_X\",  # Only _X for this column\n",
    "    \"Trunk_COG@Footstrike_X\", \"Trunk_COG@Footstrike_Z\", \"Trunk_COG@Footstrike_Y\", \n",
    "    \"Trunk_COG@Release_X\", \"Trunk_COG@Release_Z\", \"Trunk_COG@Release_Y\", \n",
    "    \"Trunk_COG_Translation_X\", \"Trunk_COG_Translation_Z\", \"Trunk_COG_Translation_Y\", \n",
    "    \"HEIGHT\", \"MASS\"\n",
    "]\n",
    "\n",
    "# Step 1: Copy row 1 (e.g., filenames or identifiers) into column A\n",
    "filenames_row = df.iloc[0, 1:]  # Skip the first column (A)\n",
    "\n",
    "# Step 2: Extract row 2 (core labels) and row 5 (subset labels like \"X\", \"Y\", \"Z\") and row 6 (data to paste)\n",
    "variable_names_row = df.iloc[1, 1:]  # Row 2, skip first column (A)\n",
    "subset_labels_row = df.iloc[4, 1:]  # Row 5, skip first column (A)\n",
    "\n",
    "# Remove the trailing numbers from the variable names in row 2\n",
    "core_variable_names = variable_names_row.apply(lambda x: re.sub(r'_\\d+_\\d+', '', str(x)))\n",
    "\n",
    "# Step 3: Extract data from row 6 (to paste) and initialize an empty DataFrame for the restructured data\n",
    "data_row = df.iloc[5, 1:]  # Row 6, skip first column (A)\n",
    "df_restructured = pd.DataFrame(columns=['Filename'] + target_columns)\n",
    "\n",
    "# Step 4: Cut the data in blocks of 17 cells and paste them into the correct columns\n",
    "block_size = 17\n",
    "for block_start in range(0, len(data_row), block_size):\n",
    "    # Extract the current block of data (cutting out 17 cells at a time)\n",
    "    data_block = data_row[block_start:block_start + block_size]\n",
    "    \n",
    "    # Initialize matched data row with None values\n",
    "    matched_data = [None] * len(target_columns)\n",
    "    \n",
    "    # Step 5: Paste the block into the correct columns:\n",
    "    # Apply the exact logic for both \"Trunk_COG\" and \"Lead_Leg_GRF\" variables, checking both row 2 and row 5\n",
    "    for i, (core_name, subset_label) in enumerate(zip(core_variable_names, subset_labels_row)):\n",
    "        if i >= block_start and i < block_start + block_size:\n",
    "            for j, target_col in enumerate(target_columns):\n",
    "                # Handle \"Trunk_COG\" and \"Lead_Leg_GRF\" variables with \"_X\", \"_Y\", \"_Z\" matching both row 2 and row 5\n",
    "                if \"Trunk_COG\" in target_col or \"Lead_Leg_GRF\" in target_col:\n",
    "                    # Match both the core name (row 2) and the subset label (row 5)\n",
    "                    if core_name in target_col and subset_label in target_col:\n",
    "                        matched_data[j] = data_block.iloc[i - block_start]\n",
    "                        break\n",
    "                # For \"Lead_Leg_GRF_Mag@Max_Shoulder_Rot\" only match _X, no _Y or _Z\n",
    "                elif \"Lead_Leg_GRF_Mag@Max_Shoulder_Rot_X\" in target_col and \"Lead_Leg_GRF_Mag@Max_Shoulder_Rot\" in core_name:\n",
    "                    matched_data[j] = data_block.iloc[i - block_start]\n",
    "                    break\n",
    "                # For other variables without subset labels, just match core name (row 2)\n",
    "                elif target_col in core_name:\n",
    "                    matched_data[j] = data_block.iloc[i - block_start]\n",
    "                    break\n",
    "    \n",
    "    # Step 6: Create a new DataFrame row with the filename and matched data\n",
    "    filename = filenames_row.iloc[block_start] if block_start < len(filenames_row) else None\n",
    "    new_row = pd.DataFrame([[filename] + matched_data], columns=df_restructured.columns)\n",
    "    \n",
    "    # Append the new row to the restructured DataFrame\n",
    "    df_restructured = pd.concat([df_restructured, new_row], ignore_index=True)\n",
    "\n",
    "# Step 7: Save the restructured file to the specified path\n",
    "output_path = 'C:/Users/q/Downloads/restructured_file_with_final_lead_leg_mag_x.csv'\n",
    "df_restructured.to_csv(output_path, index=False)\n",
    "\n",
    "# Output the file path for verification\n",
    "print(f\"Restructured file saved to: {output_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restructured file saved to: C:/Users/q/Downloads/restructured_file_with_final_lead_leg_mag_x.csv\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T17:09:41.414536Z",
     "start_time": "2024-09-11T17:09:40.956385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the CSV file\n",
    "file_path = 'C:\\\\Users\\\\q\\\\Downloads\\\\WF data2.csv'  # Adjust based on your local path\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Define the target columns, including both core names and subset labels for \"Trunk_COG\" like \"X\", \"Y\", and \"Z\"\n",
    "target_columns = [\n",
    "    \"Lead_Leg_GRF_mag_max\", \"Lead_Leg_GRF_max\", \"Lead_Leg_GRF_min\", \n",
    "    \"Lead_Leg_GRF_mag_Midpoint_FS_Release\", \"Lead_Leg_GRF@Midpoint_FS_Release\", \"Lead_Leg_GRF@Midpoint_FS_Release\",\n",
    "    \"Lead_Leg_GRF@Max_Shoulder_Rot\", \"Lead_Leg_GRF@Max_Shoulder_Rot\", \"Lead_Leg_GRF@Max_Shoulder_Rot\", \n",
    "    \"Trunk_COG@Footstrike_X\", \"Trunk_COG@Footstrike_Z\", \"Trunk_COG@Footstrike_Y\", \n",
    "    \"Trunk_COG@Release_X\", \"Trunk_COG@Release_Z\", \"Trunk_COG@Release_Y\", \n",
    "    \"Trunk_COG_Translation_X\", \"Trunk_COG_Translation_Z\", \"Trunk_COG_Translation_Y\", \n",
    "    \"HEIGHT\", \"MASS\"\n",
    "]\n",
    "\n",
    "# Step 1: Copy row 1 (e.g., filenames or identifiers) into column A\n",
    "filenames_row = df.iloc[0, 1:]  # Skip the first column (A)\n",
    "\n",
    "# Step 2: Extract row 2 (core labels) and row 5 (subset labels \"X\", \"Y\", \"Z\") and row 6 (data to paste)\n",
    "variable_names_row = df.iloc[1, 1:]  # Row 2, skip first column (A)\n",
    "subset_labels_row = df.iloc[4, 1:]  # Row 5, skip first column (A)\n",
    "core_variable_names = variable_names_row.apply(lambda x: re.sub(r'_\\d+_\\d+', '', str(x)))\n",
    "\n",
    "# Step 3: Extract data from row 6 (to paste) and initialize an empty DataFrame for the restructured data\n",
    "data_row = df.iloc[5, 1:]  # Row 6, skip first column (A)\n",
    "df_restructured = pd.DataFrame(columns=['Filename'] + target_columns)\n",
    "\n",
    "# Step 4: Cut the data in blocks of 17 cells and paste them into the correct columns\n",
    "block_size = 17\n",
    "for block_start in range(0, len(data_row), block_size):\n",
    "    # Extract the current block of data (cutting out 17 cells at a time)\n",
    "    data_block = data_row[block_start:block_start + block_size]\n",
    "    \n",
    "    # Initialize matched data row with None values\n",
    "    matched_data = [None] * len(target_columns)\n",
    "    \n",
    "    # Step 5: Paste the block into the correct columns:\n",
    "    # For \"Trunk_COG\" variables, match both row 2 and row 5 (core name + subset label)\n",
    "    # For other variables, only match row 2 (core name)\n",
    "    for i, (core_name, subset_label) in enumerate(zip(core_variable_names, subset_labels_row)):\n",
    "        if i >= block_start and i < block_start + block_size:\n",
    "            for j, target_col in enumerate(target_columns):\n",
    "                # Handle \"Trunk_COG\" variables - check both core name and \"x\"/\"y\"/\"z\" in row 5\n",
    "                if \"Trunk_COG\" in target_col:\n",
    "                    # Match both the core name (row 2) and the subset label (row 5)\n",
    "                    if core_name in target_col and subset_label in target_col:\n",
    "                        matched_data[j] = data_block.iloc[i - block_start]\n",
    "                        break\n",
    "                # For non-\"Trunk_COG\" variables, just match core name (row 2)\n",
    "                elif target_col in core_name:\n",
    "                    matched_data[j] = data_block.iloc[i - block_start]\n",
    "                    break\n",
    "    \n",
    "    # Step 6: Create a new DataFrame row with the filename and matched data\n",
    "    filename = filenames_row.iloc[block_start] if block_start < len(filenames_row) else None\n",
    "    new_row = pd.DataFrame([[filename] + matched_data], columns=df_restructured.columns)\n",
    "    \n",
    "    # Append the new row to the restructured DataFrame\n",
    "    df_restructured = pd.concat([df_restructured, new_row], ignore_index=True)\n",
    "\n",
    "# Step 7: Save the restructured file to the specified path\n",
    "output_path = 'C:/Users/q/Downloads/restructured_file_fixed_columns_correct_final.csv'\n",
    "df_restructured.to_csv(output_path, index=False)\n",
    "\n",
    "# Output the file path for verification\n",
    "print(f\"Restructured file saved to: {output_path}\")\n"
   ],
   "id": "5aad551de3df47de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw content of row 1:\n",
      "1        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "2        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "3        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "4        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "5        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "                               ...                        \n",
      "13036    Tanner Myatt\\Baseball Right-handed\\Report_TM.c...\n",
      "13037    Tanner Myatt\\Baseball Right-handed\\Report_TM_e...\n",
      "13038    Tanner Myatt\\Baseball Right-handed\\Report_TM_e...\n",
      "13039    Webb, Chase\\Baseball Right-handed\\Report_CW.cm...\n",
      "13040    Webb, Chase\\Baseball Right-handed\\Report_CW.cm...\n",
      "Name: 0, Length: 13040, dtype: object\n",
      "Columns identified as Fastball:\n",
      "1        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "2        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "3        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "4        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "5        Bryant, Luke 08-24\\Baseball Right-handed\\Repor...\n",
      "                               ...                        \n",
      "13036    Tanner Myatt\\Baseball Right-handed\\Report_TM.c...\n",
      "13037    Tanner Myatt\\Baseball Right-handed\\Report_TM_e...\n",
      "13038    Tanner Myatt\\Baseball Right-handed\\Report_TM_e...\n",
      "13039    Webb, Chase\\Baseball Right-handed\\Report_CW.cm...\n",
      "13040    Webb, Chase\\Baseball Right-handed\\Report_CW.cm...\n",
      "Name: 0, Length: 13040, dtype: object\n",
      "Extracted data from row 6 for Fastball columns:\n",
      "1        1943.5597\n",
      "2        1715.1165\n",
      "3        -940.8028\n",
      "4        1756.6207\n",
      "5        1496.6176\n",
      "           ...    \n",
      "13036      102.058\n",
      "13037       1.9558\n",
      "13038      102.058\n",
      "13039       1.8542\n",
      "13040       83.007\n",
      "Name: 5, Length: 13040, dtype: object\n",
      "Restructured file saved to: C:/Users/q/Downloads/restructured_file_fixed_fastball.csv\n",
      "Number of Fastball columns: 13040\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0e9d19718282a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
